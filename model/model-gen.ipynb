{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tamil-adjustment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "german-fellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58587\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(r'path')\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "swiss-quick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58587 files belonging to 4 classes.\n",
      "Using 41011 files for training.\n",
      "Found 58587 files belonging to 4 classes.\n",
      "Using 17576 files for validation.\n",
      "['L', 'M', 'N', 'R']\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "img_height = 85\n",
    "img_width = 85\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    interpolation=\"bicubic\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.3,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    interpolation=\"bicubic\",\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "british-technical",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 85, 85, 3)         0         \n",
      "_________________________________________________________________\n",
      "random_contrast (RandomContr (None, 85, 85, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 83, 83, 6)         168       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 41, 41, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 39, 39, 8)         440       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 19, 19, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 14)        1022      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 14)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                35880     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 164       \n",
      "=================================================================\n",
      "Total params: 39,314\n",
      "Trainable params: 39,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1./255,input_shape=(img_height, img_width, 3)),\n",
    "    layers.experimental.preprocessing.RandomContrast(0.1),\n",
    "    layers.Conv2D(6, (3,3),strides=1, activation='relu',use_bias=True),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(8, (3,3), activation='relu',use_bias=True),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(14, (3,3), activation='relu',use_bias=True),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(40, activation='relu'),\n",
    "    layers.Dense(40, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0003)\n",
    "model.compile(\n",
    "  optimizer = optimizer,\n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pressing-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'path\\logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=path, histogram_freq=1)\n",
    "\n",
    "checkpoint_filepath = r'path\\checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "grave-wisdom",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "4102/4102 [==============================] - 69s 16ms/step - loss: 0.9222 - accuracy: 0.6162 - val_loss: 0.4962 - val_accuracy: 0.8071\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\georg\\Desktop\\projects\\Bob\\checkpoint\\assets\n",
      "Epoch 2/11\n",
      "4102/4102 [==============================] - 67s 16ms/step - loss: 0.4925 - accuracy: 0.8067 - val_loss: 0.4262 - val_accuracy: 0.8298\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\georg\\Desktop\\projects\\Bob\\checkpoint\\assets\n",
      "Epoch 3/11\n",
      "4102/4102 [==============================] - 68s 17ms/step - loss: 0.4266 - accuracy: 0.8310 - val_loss: 0.3985 - val_accuracy: 0.8443\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\georg\\Desktop\\projects\\Bob\\checkpoint\\assets\n",
      "Epoch 4/11\n",
      "4102/4102 [==============================] - 68s 17ms/step - loss: 0.3973 - accuracy: 0.8403 - val_loss: 0.3645 - val_accuracy: 0.8529\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\georg\\Desktop\\projects\\Bob\\checkpoint\\assets\n",
      "Epoch 5/11\n",
      "4102/4102 [==============================] - 68s 17ms/step - loss: 0.3705 - accuracy: 0.8495 - val_loss: 0.3628 - val_accuracy: 0.8547\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\georg\\Desktop\\projects\\Bob\\checkpoint\\assets\n",
      "Epoch 6/11\n",
      "4102/4102 [==============================] - 68s 16ms/step - loss: 0.3561 - accuracy: 0.8559 - val_loss: 0.3493 - val_accuracy: 0.8607\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\georg\\Desktop\\projects\\Bob\\checkpoint\\assets\n",
      "Epoch 7/11\n",
      "4102/4102 [==============================] - 66s 16ms/step - loss: 0.3420 - accuracy: 0.8593 - val_loss: 0.3394 - val_accuracy: 0.8606\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\georg\\Desktop\\projects\\Bob\\checkpoint\\assets\n",
      "Epoch 8/11\n",
      "4102/4102 [==============================] - 65s 16ms/step - loss: 0.3282 - accuracy: 0.8639 - val_loss: 0.3364 - val_accuracy: 0.8653\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\georg\\Desktop\\projects\\Bob\\checkpoint\\assets\n",
      "Epoch 9/11\n",
      "4102/4102 [==============================] - 65s 16ms/step - loss: 0.3186 - accuracy: 0.8690 - val_loss: 0.3273 - val_accuracy: 0.8678\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\georg\\Desktop\\projects\\Bob\\checkpoint\\assets\n",
      "Epoch 10/11\n",
      "4102/4102 [==============================] - 68s 17ms/step - loss: 0.3086 - accuracy: 0.8711 - val_loss: 0.3230 - val_accuracy: 0.8705\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\georg\\Desktop\\projects\\Bob\\checkpoint\\assets\n",
      "Epoch 11/11\n",
      "4102/4102 [==============================] - 69s 17ms/step - loss: 0.3029 - accuracy: 0.8750 - val_loss: 0.3179 - val_accuracy: 0.8728\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\georg\\Desktop\\projects\\Bob\\checkpoint\\assets\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  batch_size=500,\n",
    "  epochs=11,\n",
    "  callbacks=[model_checkpoint_callback,tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lucky-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "graphic-drain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13880), started 0:14:15 ago. (Use '!kill 13880' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-eb58823de1d9b0b6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-eb58823de1d9b0b6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "attached-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = tf.keras.models.load_model('checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incorrect-portrait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\georg\\AppData\\Local\\Temp\\tmptyil6m1e\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49536"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "open(\"type3.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "through-memphis",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BatchDataset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e5cb4b876385>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'BatchDataset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-preliminary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-tobacco",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}